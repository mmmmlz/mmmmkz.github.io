<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>luomian&#39;s Site</title>
  
  <subtitle>keep learning</subtitle>
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2022-12-03T09:57:59.880Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>mmmmlz</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Learning Representations for Counterfactual Inference</title>
    <link href="http://example.com/2022/12/03/paper20221203/"/>
    <id>http://example.com/2022/12/03/paper20221203/</id>
    <published>2022-12-03T14:46:54.000Z</published>
    <updated>2022-12-03T09:57:59.880Z</updated>
    
    <content type="html"><![CDATA[<p>最近工作中用到因果推理相关知识，发现自己基础太弱，读读论文填充一下。</p><h1 id="abstract">Abstract</h1><blockquote><p>Observational studies are rising in importance due to the widespreadaccumulation of data in fields such as healthcare, education, employmentand ecology. We consider the task of answering counterfactual questionssuch as, “Would this patient have lower blood sugar had she received adifferent medication?”. We propose a new algorithmic framework forcounterfactual inference which brings together ideas from domainadaptation and representation learning. In addition to a theoreticaljustification, we perform an empirical comparison with previousapproaches to causal inference from observational data. Our deeplearning algorithm significantly outperforms the previousstate-of-the-art.</p></blockquote><p>​本文主要解决的问题类似于：对于一个患有低血糖的病人来说，接受不同的治疗方式是否是有用的？为了解决这个问题，本文基于域自适应和表征学习提出了一个用于进行反事实推理的算法框架。​这里的域自适应指的是我们在一种样本集上训练出来的模型应该在该数据集的各领域内都是适应的，有点拗口，举个例子，我们希望预测对一个病人使用某种治疗手段是否会让它对病情好转，那么不管这个病人是高中学历还是大学学历，模型的预测结果都是一样的。但是我们实际的训练样本中，大多数的病人都是高中学历，那么我们使用这个模型去预测大学学历的病人时，效果就不一定会好。</p><p>​本文将域自适应和反事实的推理进行了结合，主要方法是提出了一种正则公式让处于不同干预的人群的representations的分布更加接近，后面会详细介绍是怎么做的，本文的主要contributions有以下两点：<span id="more"></span></p><ul><li><p>我们证明了如何将反事实推理问题看作一个域自适应问题，也可以看作一个特殊的协变量转移问题。</p></li><li><p>我们推导出一系列反事实推理的表征算法。一种是基于线性模型和变量选择，另一种是基于表征的深度学习结构。</p><p>最后，我们的方法要优于基于重加权的样本采样方式,证明了拉进treatment组和control组特征表示对于反事实的推理是有益的。</p></li></ul><h1 id="problem-setup">Problem Setup</h1><p>​这一节作者介绍了一些在因果推理领域常用的定义及标识，这里简单介绍一下。</p><ul><li><span class="math inline">\(\tau\)</span>:我们希望去预估的一些潜在的干预或者行为。比如对于低血糖的病人来说，我们有两种治疗手段。<span class="math inline">\(t\in\tau\)</span></li><li><span class="math inline">\(\chi\)</span>:用户侧的特征，代表这些病人的背景（contexts),<span class="math inline">\(x\in\chi\)</span></li><li><span class="math inline">\(y\)</span>:施加某种干预后的结果，例如给病人采用A手段进行治疗后血糖增加了多少。<span class="math inline">\(Y_t(x)\in y\)</span></li></ul><p>​ 我们希望计算的是<em>individualized treatment effect</em>(ITE)：<span class="math inline">\(Y_1(x)-Y_0(x)\)</span>，但是在现实情况下，我们只能得到对用户施加两种treatment的其中一种的outcome。所以通常我们会计算拥有相似分布<span class="math inline">\(x\)</span>的人群计算他们的<em>average treatmenteffect</em>(ATE):<span class="math inline">\(ATE=E[Y_1(x)−Y_0(x)]\)</span>。一个更常用的方法是通过模型去预估ITE。<span class="math display">\[\hat{ITE}(x_i) =\left\{\begin{aligned}y_i ^F-h(x_i,1-t_i), t=1\\h(x_i,1-t_i)-y_i ^F, t=0\end{aligned}\right.\]</span> ​ 其中<span class="math inline">\(y_i^F(x)\)</span>是我们观察到的事实结果，<span class="math inline">\(y_i^{CF}\)</span>是模型预估出来的反事实结果。这种方式不同于普通的深度学习建模，会有如下问题：假设我们观察到的样本为集合<span class="math inline">\(\hat{P}^F=\left\{x_i,t_i\right\}^n_{i=1}\)</span>，在计算ITE时我们需要计算这群样本另一个treatment下的结果<span class="math inline">\(\hat{P}^{CF}=\left\{x_i,1-t_i\right\}^n_{i=1}\)</span>。我们定义<span class="math inline">\(P^F\)</span>是<span class="math inline">\(\hat{P}^F\)</span>经过模型抽取特征后到分布<em>factualdistribution</em>，同理<span class="math inline">\(P^{CF}\)</span>是<span class="math inline">\(\hat{P}^{CF}\)</span>经过模型抽取特征后到分布<em>counterfactualdistribution</em>。显然这两个分布是不相等的，但如果这个分布的差异较大的话，模型可能会侧重学习到这两个分布的不同对于最终outcome的影响，而不是我们的treatment对于outcome的影响。在深度学习中这被叫做<em>covariateshift</em>，同时这也是一种域自适应问题。举个列子，在进行随机实验时，不同的人群获得不同treatment的概率应该是随机的，但是在实际的观察研究中，往往有很多因素影响着treament的发放，这就导致了<span class="math inline">\(t\)</span>与<span class="math inline">\(x\)</span>不独立。所以上述的两个分布的差异会比较大。</p><h1 id="balancing-counterfactual-regression">Balancing counterfactualregression</h1><p>​ 我们的方法如下图所示，首先我们对于Context学习一个表达<span class="math inline">\(\Phi:\chi \to\mathbb{R}^d\)</span>,这里我们可以使用深度网络也可以使用类似对样本进行加权筛选的方式。同时我去学习一个函数<span class="math inline">\(h\)</span>，这个函数通过预估对当前的用户表征施加不同的treatment后的结果，会同时权衡三个目标：1）使得我们能够观察到的正常样本的预测误差尽可能小。2）使得对于反事实样本的预测的误差尽可能小，这里对于反事实样本，由于我们并没有它的真实label，我们可以通过一些方式来构建一个伪label（后面会讲）。3）这个函数还要对不同干预下的representation进行一个平衡。​针对第一点，可以通过使用最小化error和一些正则方式来确保这个误差尽可能小，第二点，我们利用的是最近邻的方法，来构造反事实，即<span class="math inline">\(y_{i:t_i=0}^{CF}=y_{NN_i:i\neq0}^{CF}\)</span>其中<span class="math inline">\(NN_i\)</span>表示最近邻的邻居。本质是在模拟样本的反事实，有点类似于matching的方法。平衡好不同干预下的representation。第三点，我们通过最小化<em>discrepancydistance</em>这是域自适应的距离度量公式，后文会有详细介绍。</p><p>​直观地说，减少treatment人群和control人群之间差异的表示防止模型在试图从事实领域推广到反事实领域时使用数据的“unreliable”方面。例如，如果在我们的样本中，几乎没有男性接受过药物A，那么推断男性对药物A的反应很容易出错，因此可能需要更谨慎地使用性别特征。</p><figure><img src="/Users/mlz/Library/Application%20Support/typora-user-images/image-20221130220036103.png" alt="image-20221130220036103"><figcaption aria-hidden="true">image-20221130220036103</figcaption></figure><p>​</p><p>​ 我们希望最小化的损失函数如下：</p><p>​<br><span class="math display">\[B_{\mathcal{H},\alpha,\gamma}(\Phi,h)=\frac{1}{n}\sum_{i=1}^n|h(\Phi(x_i),t_i)-y_i^F|+\\\alpha \\text{disc}_\mathcal{H}(\hat{P}_\Phi^F,\hat{P}_\Phi^{CF})+\frac{\gamma}{n}\sum_{i=1}^n|h(\Phi(x_i),1-t_i)-y_{j(i)}^F|\]</span></p><p>​ 上式中，<span class="math inline">\(\alpha,\gamma&gt;0\)</span>是用来控制我们对于两个分布的相似度的限制力度，其中<span class="math inline">\(\text{disc}\)</span>是在后文定义的一种度量分布之间距离的函数。<span class="math inline">\(j(i)\in \text{arg min}_{j\in{\{1...n\}} s.t.t_j=1-t_i}\)</span> 即<span class="math inline">\(j\)</span>是在样本空间里和<span class="math inline">\(i\)</span>最相近的一个样本，注意每个样本只能被选择一次。</p><h2 id="balancing-variable-selection">Balancing variable selection</h2><p>​一个简单的方法去做样本间分布的平衡是只选择那些在treatmnet组和control组分布相似的特征，但是，那些被舍弃的不相似的特征往往是对预测结果很重要的，直接把他们忽略会影响预测的准确性。一种解决方式是限制这些不相似特征对于预测结果的影响，我们基于这种方式，学习一组稀疏的权重参数，通过平衡模型的预测能力已经样本之间的相似度来确定特征的重要性。作者介绍了两种方法，1）线性模型。2）深度模型。这里主要对深度模型做一些介绍，</p><figure><img src="pic1.png" alt="pic1"><figcaption aria-hidden="true">pic1</figcaption></figure><p>​ 如上图所示，作者在标准的前馈神经网络做了一些改进，首先，<span class="math inline">\(d_r\)</span>层通过学习一个表达<span class="math inline">\(\Phi(x)\)</span>将输入特征<span class="math inline">\(x\)</span>进行映射，这一这里使用的样本是没有带上treatment特征的，同时，这一层的输出会被用来计算上文提到的<span class="math inline">\(\text{disc}_\mathcal{H}(\hat{P}_\Phi^F,\hat{P}_\Phi^{CF})\)</span>,之后的<span class="math inline">\(d_o\)</span>层会将treatment特征作为额外特征加入。同时，注意到treatment的还有一根线连接到<span class="math inline">\(\text{disc}\)</span>的计算上，这是因为我们需要这个标签来指导当前样本是属于treatment组还是control组。​为什么要在网络中间将treatment作为额外特征加入而不是在网络一开始就一起训练呢，个人理解这是因为treatment往往很稀疏，为了避免treatment特征在网络前半段被大量其他特征淹没，所以在网络中间部分加入。同时，这样生成的表征<span class="math inline">\(\Phi\)</span>也完全代表了与treatment无关的特征。</p><p>​最后作者通过一系列公式证明了上文中提到的分布差异对反事实的预测结果是有影响的，这里就不重复证明了，感兴趣可以去看原论文。最后的最后作者也指出当我们遇到多treatment情况时，可能需要更适合的算法。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;最近工作中用到因果推理相关知识，发现自己基础太弱，读读论文填充一下。&lt;/p&gt;
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;Observational studies are rising in importance due to the widespread
accumulation of data in fields such as healthcare, education, employment
and ecology. We consider the task of answering counterfactual questions
such as, “Would this patient have lower blood sugar had she received a
different medication?”. We propose a new algorithmic framework for
counterfactual inference which brings together ideas from domain
adaptation and representation learning. In addition to a theoretical
justification, we perform an empirical comparison with previous
approaches to causal inference from observational data. Our deep
learning algorithm significantly outperforms the previous
state-of-the-art.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;​
本文主要解决的问题类似于：对于一个患有低血糖的病人来说，接受不同的治疗方式是否是有用的？为了解决这个问题，本文基于域自适应和表征学习提出了一个用于进行反事实推理的算法框架。
​
这里的域自适应指的是我们在一种样本集上训练出来的模型应该在该数据集的各领域内都是适应的，有点拗口，举个例子，我们希望预测对一个病人使用某种治疗手段是否会让它对病情好转，那么不管这个病人是高中学历还是大学学历，模型的预测结果都是一样的。但是我们实际的训练样本中，大多数的病人都是高中学历，那么我们使用这个模型去预测大学学历的病人时，效果就不一定会好。&lt;/p&gt;
&lt;p&gt;​
本文将域自适应和反事实的推理进行了结合，主要方法是提出了一种正则公式让处于不同干预的人群的representations的分布更加接近，后面会详细介绍是怎么做的，本文的主要contributions有以下两点：&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://example.com/2022/12/03/testformer/"/>
    <id>http://example.com/2022/12/03/testformer/</id>
    <published>2022-12-03T09:14:25.017Z</published>
    <updated>2022-12-03T09:14:25.017Z</updated>
    
    <content type="html"><![CDATA[<p>我的测试公式<span class="math inline">\(y_i\)</span>带我飞</p><p>但是是多少 <span class="math display">\[min(x_j-y_j)\]</span></p><p>稍等</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;我的测试公式&lt;span class=&quot;math inline&quot;&gt;\(y_i\)&lt;/span&gt;带我飞&lt;/p&gt;
&lt;p&gt;但是是多少 &lt;span class=&quot;math display&quot;&gt;\[
min(x_j-y_j)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;稍等&lt;/p&gt;
</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>init</title>
    <link href="http://example.com/2022/11/15/init/"/>
    <id>http://example.com/2022/11/15/init/</id>
    <published>2022-11-15T06:07:53.000Z</published>
    <updated>2022-11-15T06:07:53.352Z</updated>
    
    <content type="html"><![CDATA[]]></content>
    
    
      
      
    <summary type="html">
</summary>
      
    
    
    
    
  </entry>
  
</feed>
