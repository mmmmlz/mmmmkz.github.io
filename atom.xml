<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>luomian&#39;s Site</title>
  
  <subtitle>keep learning</subtitle>
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2022-11-26T13:59:59.225Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>mmmmlz</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title></title>
    <link href="http://example.com/2022/11/26/uplift%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%9D%83%E7%9B%8A%E5%AE%9A%E4%BB%B7%E4%B8%8A%E7%9A%84%E5%BA%94%E7%94%A82/"/>
    <id>http://example.com/2022/11/26/uplift%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%9D%83%E7%9B%8A%E5%AE%9A%E4%BB%B7%E4%B8%8A%E7%9A%84%E5%BA%94%E7%94%A82/</id>
    <published>2022-11-26T13:59:59.225Z</published>
    <updated>2022-11-26T13:59:59.225Z</updated>
    
    <content type="html"><![CDATA[<h1 id="背景">背景</h1><p>在研究如何对用户&amp;商品进行权益加码时，我们需要知道当前用户对当前商品在不加权益/加不同程度的权益的情况下的ctr/cvr/ctcvr。这里我们使用因果推理的方法，用uplift模型来预估 不加权益/加不同权益对用户下单概率的影响。 ## problem setting假设我们有用户&amp;商品的特征<spanclass="math inline">\(X\)</span>,和准备加码的权益<spanclass="math display">\[treatment_i\]</span>,其中<spanclass="math inline">\(i=0\)</span>表示不发放权益，<spanclass="math inline">\(i=1,2,3...\)</span>表示发放金额为1，2，3...的权益。<spanclass="math inline">\(Y^0\)</span>是不发放权益时的<spanclass="math inline">\(outcome\)</span>，<spanclass="math inline">\(Y^i\)</span>是发放权益为<spanclass="math inline">\(i\)</span>时的<spanclass="math inline">\(outcome\)</span>。我们的目标是得到一个满足下式的权益值<spanclass="math inline">\(i\)</span>。 <spanclass="math inline">\(\text{max} \sum_iY^i-Y^0|x\)</span>实际操作时这个式子会增加gmv，单量，成本等约束条件。但不影响我们的核心问题，预估<spanclass="math inline">\(Y^i\)</span>。干预问题和传统的Ml模型ML监督模型都是由label的，而因果干预问题是缺失label的，即对于同一条流量（用户&amp;商品），我们只知道他不发权益/发某一种权益后的label，其他结果都是反事实的。对于这个问题，在训练时我们可以通过预估<strong>CATE</strong>来代替<strong>ITE。</strong><strong>ITE：individual treatment effect</strong> <spanclass="math inline">\(ITE=Yi(T=1)−Yi(T=0)\)</span> <strong>ATE：averagetreatment effect</strong> <spanclass="math inline">\(ATE=E[Y(T=1)−Y(T=0)]\)</span><strong>CATE：conditional average treatment effect</strong> <spanclass="math inline">\(CATE=E[Y(T=1)−Y(T=0)|X=x]\)</span> ## 模型 ###基于树的方法——倾向评分树（Propensity Tree）该类方法是基于决策树或者决策森林进行因果效应的估计，可以看作一种邻居参数可调整的最近邻方法。处于相同叶子节点的样本，被认为距离最近。该方法以数据中的协变量作为输入，基于分类回归树（CART）对干预变量进行预测，构成一个倾向得分估计器。最终每个样本的因果效应估计值就在对应的叶子节点中进行计算。因为每个叶子节点中的样本具有最接近的倾向性得分，通过CART将其匹配起来。### 元学习方法（Meta Learners）<strong>S-Learner，T-Learner，X-Learner</strong> <imgsrc="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/50856451/1669205827375-bd429a5d-c284-4f2b-98a9-d0a331fdddf2.png#clientId=u02183c15-ba16-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=176&amp;id=ucc991c7b&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=352&amp;originWidth=800&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=172836&amp;status=done&amp;style=none&amp;taskId=ub5b8ede4-c4bd-4fc6-b182-412cfc878bc&amp;title=&amp;width=400"alt="image.png" /> <imgsrc="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/50856451/1669205842332-0125d96f-305f-4949-8821-f98e836f757a.png#clientId=u02183c15-ba16-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=161&amp;id=u5206b6d1&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=322&amp;originWidth=906&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=190576&amp;status=done&amp;style=none&amp;taskId=ue6920c24-d140-45a0-b76b-89b37c6fc6a&amp;title=&amp;width=453"alt="image.png" /> <imgsrc="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/50856451/1669205858031-ea512bea-adf2-4873-a7db-d6b1c990b0eb.png#clientId=u02183c15-ba16-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=490&amp;id=u8fd17edc&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=980&amp;originWidth=1910&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=980952&amp;status=done&amp;style=none&amp;taskId=u5663ca28-6da2-441c-9aca-2bc31fb7de7&amp;title=&amp;width=955"alt="image.png" /></p><h3id="表征学习方法representation-learning-based-model">表征学习方法（Representationlearning-based Model）</h3><h4 id="tarnet-cfr">TARNet &amp; CFR</h4><pre><code>    ![image.png](https://intranetproxy.alipay.com/skylark/lark/0/2022/png/50856451/1669206710490-7ed8a525-c437-4558-9ff6-f90ab72d4493.png#clientId=u02183c15-ba16-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=256&amp;id=u995afc27&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=512&amp;originWidth=1070&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=358297&amp;status=done&amp;style=none&amp;taskId=ued84344f-faad-4110-9e19-7ba5b720ca1&amp;title=&amp;width=535)</code></pre><p>end-to-end的两阶段模型：第一部分对所有样本拟合一个representation，第二部分分别对treatment组和control组的样本进行训练。这样的优点是第二部分使用到的特征已经是经过抽取的高维特征，在这个地方将t进行concat，可以使得t的特征不至于被其他大量特征淹没。除此之外，该网络还设计了一个IPM模块，这个模块的主要功能是为了让在第一部分结束后，treatment组的分布和control组的分布尽可能一致，这是因为在不是随机实验的情况下，可能有一种用户获得treatment的概率更高。模型可能会更加侧重对这些隐藏的协变量去学习而不是我们的t。IPM可以是任何一个度量分布相似度的函数，比如KL散度 模型最终的损失函数为：<span class="math inline">\(min_{h,\Phi} \frac{1}{n} \sum_{i=1}^nw_iL(h(\Phi(x_i),t_i),y_i)+\lambda R(h) +\alphaIPM_G(\Phi(x_i)_{i:t=0},\Phi(x_i)_{i:t=1} )\)</span>其中第一项为神经网络本身的loss，通过一个权重参数<spanclass="math inline">\(w_i\)</span>来平衡treatment组和control组样本数量的不均。第二项是一个对网络复杂度的惩罚。第三项是IPM惩罚，通过<spanclass="math inline">\(\alpha\)</span>来控制力度。 #### SITE <imgsrc="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/50856451/1669207889095-6fc171e6-0b0b-4113-97c2-55af1f5aa978.png#clientId=u02183c15-ba16-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=536&amp;id=ueea436b0&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=1072&amp;originWidth=1266&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=966525&amp;status=done&amp;style=none&amp;taskId=ub12eed6e-b22b-4e4c-a511-1e3a6dbdd87&amp;title=&amp;width=633"alt="image.png" />这篇文章的主要思路是说在进行因果建模的时候不仅仅要考虑treatment组和control组样本在表征后的分布要相似，还要关注局部样本的相似性。文章通过选取样本集中的极端样本(hardsamples)来评估局部相似。</p><ol type="1"><li><strong>样本的选择</strong></li></ol><p>首先会计算每个样本的Propensity score，<spanclass="math inline">\(P(x)=P(T=1|X=x)\)</span>，选择 <spanclass="math inline">\(x_i\)</span>,<spanclass="math inline">\(x_j\)</span>,在treatment组和control组分别选择一个Propensityscore最接近0.5的样本，其中 <spanclass="math inline">\(x_i\)</span>属于treatment组；这样选出两个最接近的分处不同组的样本组成第一个样本对。<imgsrc="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/50856451/1669463229890-d7ae0ac9-9d2b-4c0c-8992-c338221e6e36.png#clientId=u2034b42f-813e-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=94&amp;id=u3c0e0fd6&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=188&amp;originWidth=1120&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=38316&amp;status=done&amp;style=none&amp;taskId=ucf67c36a-03af-44da-93b3-006218c60ff&amp;title=&amp;width=560"alt="image.png" /> <imgsrc="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/50856451/1669463367050-e5dff41a-d9ce-41c5-97c8-76a3ac732b30.png#clientId=u2034b42f-813e-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=51&amp;id=udff62f00&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=102&amp;originWidth=966&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=18836&amp;status=done&amp;style=none&amp;taskId=u894b0c96-bf92-4037-999a-d6ff517a72f&amp;title=&amp;width=483"alt="image.png" /> <imgsrc="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/50856451/1669463404578-9b47f9c8-7e85-410a-9d43-4b0259a6c962.png#clientId=u2034b42f-813e-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=62&amp;id=uf71c1636&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=123&amp;originWidth=1120&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=18846&amp;status=done&amp;style=none&amp;taskId=u0c371566-c243-431e-9aa5-530790a39cf&amp;title=&amp;width=560"alt="image.png" />接着按照上图的方式找出6个样本，这样选择出的样本处于整体样本空间的中间和边缘位置，是最具有代表性的。</p><ol start="2" type="1"><li><strong>Position-Dependent Deep Metric(PDDM)(衡量局部相似性的PDDM)</strong></li></ol><figure><imgsrc="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/50856451/1669463959291-fbe806dc-6d8c-432e-94f8-e4858eeff827.png#clientId=u2034b42f-813e-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=159&amp;id=u688c506a&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=318&amp;originWidth=1818&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=271058&amp;status=done&amp;style=none&amp;taskId=ucf4ae1ee-3134-4752-84a3-471c9e8af5f&amp;title=&amp;width=909"alt="image.png" /><figcaption aria-hidden="true">image.png</figcaption></figure><p>PDDM的loss如上，其中 <imgsrc="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/50856451/1669464043378-2c8df2a8-a44e-4af6-a5f2-8b1f824d54e0.png#clientId=u2034b42f-813e-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=46&amp;id=u279813b2&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=92&amp;originWidth=628&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=31112&amp;status=done&amp;style=none&amp;taskId=u7e7789f7-20f4-497a-89df-31c229f5bbb&amp;title=&amp;width=314"alt="image.png" /> <imgsrc="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/50856451/1669464017169-7eb01d8d-6a87-410b-a692-c5857cc4bcc2.png#clientId=u2034b42f-813e-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=184&amp;id=u01a474d5&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=368&amp;originWidth=764&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=147190&amp;status=done&amp;style=none&amp;taskId=ubb3e6af8-8b13-4158-8bf9-722609d85da&amp;title=&amp;width=382"alt="image.png" /></p><ol start="3" type="1"><li><strong>Middle Point Distance Minimization(MPDM)(衡量均衡性的PDDM)</strong></li></ol><p>CRF的IPM模块通过衡量两个分布的相似度来进行treatment组和control组分布的控制，SITE通过MPDM模块来达到这个目的，还是用选择的6个样本，作者希望这6个样本中，treatment组和control组的样本的中心点要尽可能接近。<imgsrc="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/50856451/1669464501872-72de4a22-fb5a-4772-ab4b-381968590d81.png#clientId=u2034b42f-813e-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=283&amp;id=u71ec5518&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=566&amp;originWidth=1298&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=422715&amp;status=done&amp;style=none&amp;taskId=u2d011382-5ec4-43de-b37c-845ec61cb26&amp;title=&amp;width=649"alt="image.png" /></p><h1 id="uplift模型评估">uplift模型评估</h1><p>上面说到我们在训练时通过预估CATE来代替ITE，但是在进行模型评估时，虽然我们可以通过模型预估出一个样本在不同treatment下的outcome，能够计算每个样本的ITE，但我们如何评估这个ITE计算是否准确呢？Qini curve给出的方案是，将每个样本我们预估出来的ITE由大到小进行排序，然后依次计算每一部分样本中的真实ATE（注意这里我们是没发计算真实的ITE的）。最后通过和随机排序的结果相比较来评估模型的性能。## Qini curve <imgsrc="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/50856451/1669202347155-208479f5-75aa-41ac-8085-df6e6a0d909d.png#clientId=u671a4cf4-8c62-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=327&amp;id=uc3fb1475&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=654&amp;originWidth=986&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=368956&amp;status=done&amp;style=none&amp;taskId=u0755561c-5ca0-411b-845b-cc969707f9d&amp;title=&amp;width=493"alt="image.png" /> <strong>为什么要用uplift score排序？</strong>因为我们评估的是模型的uplift能力，而不是ctr或者cvr的准确度，upliftscore代表了每个样本对权益的敏感度，把敏感度相似的样本聚集起来，可以更好的用ATE来近似得到ITE。理论上来说，uplift score 最大的样本应该是<spanclass="math inline">\(Y=1｜T=1\)</span>的样本，最差的是<spanclass="math inline">\(Y=0｜T=1\)</span>的样本，我们希望模型能够找出这些样本，并且将它们的uplift得分尽可能高，所以，按照upliftscore 排序可以让这些样本聚集起来。<strong>纵轴为什么是这样计算？</strong> 按照upliftscore排序后，因为一个样本不可能同时处于treatment组和control组，所以我们每次取前<spanclass="math inline">\(k\%\)</span>的样本,我们想要评估的是模型到底有没有将那些真正的ITE高的样本找出来，这里我们用这一小组样本的ATE来近似ITE，ATE的计算方式为<span class="math inline">\(\frac{R^T_k(k)}{N^T_\pi(k)}-\frac{R^C_\pi(k)}{N^C_\pi(k)}\)</span>，其实换个角度，就是实验组的CTR-对照组的CTR，也就是真实的uplift。<strong>为什么要降序？</strong>为了比较不同模型的好坏，一个好的模型会将真正uplift高的样本预估出较高的uplift得分，从而将它排在前面，这就可以增大这条曲线与base曲线的面积。### AUUC AUUC就是上图中uplift curve和baseline之间的面积。</p><h1 id="现状遇到的问题">现状&amp;遇到的问题</h1><h2 id="现状">现状</h2><p>模型采用S-learn的架构，使用ctr，cvr两个目标进行建模。特征使用原始的ctr，cvr，和权益相关特征。</p><h2 id="遇到的问题样本偏差">遇到的问题——样本偏差</h2><p>在实际进行模型训练以及评估时，虽然我们采用的是随机撒点实验的数据，整体上避免了用户潜在的协变量对于是否发treatment的影响，即<strong>从用户视角来看</strong>，我们对他发与不发是完全随机的。但还是有一个问题：我们采取的撒点规则是，每一个cps商品在<spanclass="math inline">\([0,price*rate]\)</span>内以及10分前为间隔进行撒点，这样是为了保证不会有亏本的加码情况出现。但是这样导致了一个问题，<strong>从商品视角来看</strong>，我们的随机实验不是真随机，而是在每个商品的单价和佣金率的限制下的分层随机。这样会有两个问题</p><ol type="1"><li>训练阶段：高单价<em>佣金率的商品，有机会能撒到更高的权益值，且发权益的概率也偏大，而低单价</em>佣金率的商品，没有机会发出高权益值，且发权益的概率相对较低，违背了可忽略性假设（Ignorability），即<spanclass="math inline">\(x\bot \text{T}|\text{x}\)</span></li><li>预测阶段：这些低单价的商品还有着较高的点击率。这就导致了我们计算出来的这些大部分的低单价的不发权益的流量，<strong>它们的ITE会被低估</strong>（不发的ctr较高，发的权益较低导致ctr几乎没有提升）。</li></ol><p>最终在计算样本整体的ATE的时候，我们按照 <spanclass="math inline">\(\frac{R^T_k(k)}{N^T_\pi(k)}-\frac{R^C_\pi(k)}{N^C_\pi(k)}\)</span>计算出来的真实ATE是有偏的，因为这些聚集在一起的样本会有隐藏的协变量(价格&amp;佣金率)对是否发放treatment有影响。</p><p>解决方案： <strong>重加权方法（Re-weighting methods）</strong>样本重加权是一种解决选择偏差的高效方法。通过为每个样本分配合适的权重，使得干预组与对照组分布类似。在这种方法中，最关键的概念就是平衡分数<spanclass="math inline">\(b(x)\)</span>，其为x的函数且满足T⊥x|b(x)。其中，倾向评分（Propensityscore）是平衡分数的一个特例，也是最常见的一种：<spanclass="math inline">\(P(x)=P(T=1|X=x)\)</span>。重加权方法大致可以分成两类，分别是样本重加权和同时对样本与协变量进行重加权的方法。这里我们使用<strong>逆倾向加权（IPW）。</strong>这是基于样本重加权的代表性方法。通过为每个样本分配一个权重：<span class="math inline">\(r=\frac{T}{P(x)}+\frac{1-T}{1-P(x)}\)</span>即对于所有样本，我们先根据商品的单价&amp;佣金率，计算出该商品被加权益/不加权益的概率（Propensityscore），用treatment样本/Propensity score，control组样本/（1-Propensityscore）作为他们的权重进行训练。这样，假设一个商品的撒点范围为<spanclass="math inline">\([0,10,20]\)</span>,则其发treatment的概率为<spanclass="math inline">\(\frac{2}{3}\)</span>,不发的概率为<spanclass="math inline">\(\frac{1}{3}\)</span>,如果这个商品事实上是treatment组，则在计算他的loss时，会除以<spanclass="math inline">\(\frac{2}{3}\)</span>。如果是control组，则会除以<spanclass="math inline">\(\frac{1}{3}\)</span>。总之，对于一个treatment样本，如果他发treatment的概率越大，那他的loss权重就越小。对于一个control样本，如果他不发treatment的概率越大，那他的loss权重就越小。这样就可以解决训练时的样本不均问题。同时，由于这些ctr较高的低价商品，由于他们发treatment的概率小，模型会加大他们的loss权重，在预测时能更好的预估出他们在施加权益时的ctr，从而更准确的预估ITE。</p><h1 id="优化计划action">优化计划&amp;action</h1><ol type="1"><li><p>模型结构：目前采用的较为简单的S-learn架构，后续可以尝试X-learn等复杂结构，同时一些深度模型也可以进行实验。</p></li><li><p>调控链路评估，目前我们的评估方式是单纯的对模型进行评估，但是我们的整体链路还涉及到对费比，订单，gmv的约束，后面可以思考如何将这些问题纳入到评估框架。</p></li></ol><h2 id="section"></h2>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;背景&quot;&gt;背景&lt;/h1&gt;
&lt;p&gt;在研究如何对用户&amp;amp;商品进行权益加码时，我们需要知道当前用户对当前商品在
不加权益/加不同程度的权益的情况下的ctr/cvr/ctcvr。
这里我们使用因果推理的方法，用uplift模型来预估 不加权益/加不同权益
对用户下单概</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>init</title>
    <link href="http://example.com/2022/11/15/init/"/>
    <id>http://example.com/2022/11/15/init/</id>
    <published>2022-11-15T06:07:53.000Z</published>
    <updated>2022-11-15T06:07:53.352Z</updated>
    
    <content type="html"><![CDATA[]]></content>
    
    
      
      
    <summary type="html">
</summary>
      
    
    
    
    
  </entry>
  
</feed>
