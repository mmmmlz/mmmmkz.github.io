<!DOCTYPE html><html lang="zh-Hans" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>他山之石————推荐系统中的跨域建模 | kerwin's notebook</title><meta name="author" content="mmmmlz"><meta name="copyright" content="mmmmlz"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="推荐系统是在线服务的重要组成部分，特别是对于电子商务平台而言。在推荐系统中，转化率（CVR）预测对于优化电子商务的总交易额目标至关重要。然而，CVR存在众所周知的样本选择偏差（SSB）和数据稀疏性（DS）问题。虽然现有的方法ESMM和ESM2通过建模用户行为路径来训练所有展示样本，但是此方法也只是通过构建在某个特点场景下的行为路径来解决DS问题，而在实际的推荐系统中，面临的往往是有着不同性质的场景">
<meta property="og:type" content="article">
<meta property="og:title" content="他山之石————推荐系统中的跨域建模">
<meta property="og:url" content="http://kerwinblog.top/2023/05/25/0525/index.html">
<meta property="og:site_name" content="kerwin&#39;s notebook">
<meta property="og:description" content="推荐系统是在线服务的重要组成部分，特别是对于电子商务平台而言。在推荐系统中，转化率（CVR）预测对于优化电子商务的总交易额目标至关重要。然而，CVR存在众所周知的样本选择偏差（SSB）和数据稀疏性（DS）问题。虽然现有的方法ESMM和ESM2通过建模用户行为路径来训练所有展示样本，但是此方法也只是通过构建在某个特点场景下的行为路径来解决DS问题，而在实际的推荐系统中，面临的往往是有着不同性质的场景">
<meta property="og:locale">
<meta property="og:image" content="http://kerwinblog.top/img/11.png">
<meta property="article:published_time" content="2023-05-25T11:01:41.000Z">
<meta property="article:modified_time" content="2023-06-02T13:23:40.145Z">
<meta property="article:author" content="mmmmlz">
<meta property="article:tag" content="RS">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://kerwinblog.top/img/11.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://kerwinblog.top/2023/05/25/0525/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: 'days',
  dateSuffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  }
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '他山之石————推荐系统中的跨域建模',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-06-02 21:23:40'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/backgound.css"><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="kerwin's notebook" type="application/atom+xml">
</head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/11.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">23</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">8</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">2</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> home</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-graduation-cap"></i><span> Article</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/7.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="kerwin's notebook"><span class="site-name">kerwin's notebook</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> home</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-graduation-cap"></i><span> Article</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">他山之石————推荐系统中的跨域建模</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2023-05-25T11:01:41.000Z" title="Created 2023-05-25 19:01:41">2023-05-25</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-06-02T13:23:40.145Z" title="Updated 2023-06-02 21:23:40">2023-06-02</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/paper-Reading/">paper Reading</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word count:</span><span class="word-count">7.6k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading time:</span><span>23min</span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>推荐系统是在线服务的重要组成部分，特别是对于电子商务平台而言。在推荐系统中，转化率（CVR）预测对于优化电子商务的总交易额目标至关重要。然而，CVR存在众所周知的样本选择偏差（SSB）和数据稀疏性（DS）问题。虽然现有的方法ESMM和ESM2通过建模用户行为路径来训练所有展示样本，但是此方法也只是通过构建在某个特点场景下的行为路径来解决DS问题，而在实际的推荐系统中，面临的往往是有着不同性质的场景之间的样本稀疏问题。</p>
<p>这段时间梳理了几篇针对解决跨域建模等一系列问题的几篇论文，在这里整理一下。</p>
<h1 id="全域学习">全域学习</h1>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2303.00276.pdf">《Entire Space
Learning Framework: Unbias Conversion Rate Prediction in Full Stages of
Recommender System》</a></p>
<h2 id="方法">方法</h2>
<p>为了解决推荐链路中的样本选择偏差问题和数据稀疏问题，我们提出了基于全域学习的信息流推荐全链路无偏学习解决方案，重新构建了概率空问，充分利用了推荐系统的漏斗结构，直接建模了漏斗结构中上一阶段汳回结果到正样本的概率，使得训练与预测在推荐系統中一致，从而消除样本选择偏差；同时模型引入全网的领域知识辅助本场景的排序模型学习，将上一阶段返回结果到王样本的概率进一步拆分成上一阶段返回结果到全网正样本的概率与全网正样本概率到本场景正样本概率的乘积，有效的解決了数据稀疏问题。</p>
<h3 id="形式化定义">形式化定义</h3>
<p>我们的研究主要集中在排序阶段，以GMV优化为目标的推荐模型可以拆解为：流量X点击率X转化率X笔单价，传统对<span class="math inline">\(\text{CTR} \times
\text{CVR}\)</span>的建模方式如下：<span class="math inline">\(p_{pvTopay}=p(Click=1|Pv=1) *
p(Pay=1|Click=1)\)</span>然而这样建模存在两个问题，一个是样本选择偏差问题，加上训练数据为曝光的样本，而预测的样本为推荐系统上一阶段的结果，例如精排模型的预测样本为粗排返回的结果，粗排模型的预测样本为召回返回的结果。存在训练和预测不一致的问题，进一步产生数据闭环导致问题加重；另一个问题是数据稀疏问题，在排序阶段往往只会用到本场景的曝光样本，忽略了用户在全场景的丰富行为。因此，如何解决样本选择偏差使排序阶段的训练和预测保持一致，以及如何在推荐系统的全链路阶段均引入用户在全场景的样本是非常重要的问题。</p>
<p>基于此，我们提出了基于全域学习的信息流推荐全链路无偏学习解決方案，重新构建概率空问，作为现有概率
<span class="math inline">\(P_{PvToPay}\)</span>
的补充，同时引入用户在全网的行为，以此缓解上述问题。首先我们重新构建了概率空间，以精排模型为例，为了使训练空问与预测空间一致从而解决样本选择偏差问题，我们充分利用推荐漏斗式的结构，直接构建粗排返回结果到正样本的概率，即：<span class="math inline">\(p_{DrToPay}=p(Pay=1|Drr=1)\)</span>, 其中 <span class="math inline">\(\{Drr =1\}\)</span>
是粗排返回的结果集合。进一步的为了在排序的每个阶段均引1入用户在全网的行为从而缓解数据稀疏问题，我们将概率<span class="math inline">\(P_{DrrToPay}\)</span> 进一步拆解成如下形式： <span class="math display">\[
P_{DrrToPay}= p(Pay=1|Drr =1)=p(Pay_{all} =1|Drr =1)*p(Pay_{gul}
=1|Pay_{all} =1)
\]</span> ，其中 $p(Pay_{all} =1|Drr =1)
$是粗排返回结果到全网成交正样本的概率， <span class="math inline">\({Pay_{all} = 1}\)</span>
是粗排返口结果且用户在全网成交的样本集合，<span class="math inline">\(P(Pay_{gul}=1|Pay_{all} =1)\)</span>
是全网成交正样本到本场景成交正样本的概率，<span class="math inline">\({Pay_{gul} =
1}\)</span>是最终在本场景的成交正样本集合。这样建模有3个优点：1）统一了模型训练和预测的候选数据集，以精排模型为例其训练样本集合与预测样本集合均是粗排返回的结果集合，不再存在线上预测与
离线训练不一致的问题，缓解了样本选择偏差问题；2）在推荐系统链路阶段显示且直接地建模了用户在全网的成交行为，建模推荐系统漏斗结构中上一阶段结果到全网正样本的概率，缓解了数据稀疏问题；3）建模全网样本到本场景样本的概率，从而使得排序模型的最终建模目标为本场景的正样本，更符合本场景的心智，滅少无用信息的引入，减少适合其他场景而不适合本场景的样本曝光。
最终精排模型建模了人粗排返回结果到本场景成交的概率，公式如下： <span class="math display">\[
p_{DrrToPay} = p(Pay_{all}=1|Drr=1)*p(Pay_{gul}=1|Pay_{all}=1)
\]</span>
如上概率构建方式能够使得训练和预测的候选数据集保持一致，有效缓解数据偏差问题，同时在本场景有效引入全域领域知识，缓解数据稀疏问题。最终
<span class="math inline">\(P_{DrrToPay}\)</span>可以作为 <span class="math inline">\(P_{PvToPay}\)</span>​的补充，在线上共同进行预测，最终以
GMV 为优化目标的问题形式化如下： <span class="math display">\[
GMV = (p_{PvToPay}+ a * p_{DrrToPo}）* Price
\]</span>
粗排模型的优化目标与精排类似,不同的是候选集合用到的一阶段的召回结果集合，建模了从召回到本场景成交的概率，形式化如下：
<span class="math display">\[
P_{RecallToPay}=p(Pay_{all} =1 |Recall =1)*p（Pay_{gul} =1| Pay_{all}
=1)
\]</span></p>
<h3 id="模型">模型</h3>
<p>模型的整体结构分为两部分，左边的一部分<span class="math inline">\(p(Pay_a=1|PS=1)\)</span>建模的是上一阶段结果到全网成交的概率，右边一部分<span class="math inline">\(p(Pay_g =
1|Pay_a=1,PS=1)\)</span>建模的是全网成交到本场景成交的概率。模型的整体结构如下：</p>
<p><img src="/2023/05/25/0525/image-20230525201707274.png"></p>
<h4 id="embedding-layer">Embedding Layer</h4>
<p>模型的输入层是Embedding层，它将输入的大量稀疏特征映射到低维稠密的向量空间中，模型的输入特征主要包括用户特征画像特征、商品属性特征、上下文特征、交叉特征和行为序列特征。</p>
<h4 id="layer-normal-target-attention-layer">Layer Normal Target
Attention Layer</h4>
<p>用于处理行为序列特征，该层捕获了目标商品Target item
与用户历史行为序列的相似性，考虑向量的物理意义，我们使用内积来计算Attention，两个item越相似，权重越大；并采用Mutil-Head
Attention的方式有效的将序列特征放到多个平行的空间进行计算，提升模型的容错性和精准度。
<span class="math display">\[
Attention(Q,K,V)=softmax(\frac{QK^T}{\sqrt{d_k}})
\]</span></p>
<h4 id="mlp-layer">MLP layer</h4>
<p>得到所有特征的向量表示之后，最终将向量串联起来输入到 MLP Layer 中通过
Sigmoid 函数获得<span class="math inline">\(p(Pay_{all} =1|Drr
=1)\)</span> 。为了建模用户隐式反馈中的bias，比如 Position Bias，
很多时候用户点击某个商品井不是因为真的最喜欢这个商品，而仅仅只是因为其排序的位置比较靠前；User
Bias，不同用户的点击偏好不同，有些用户就是具有较高的点击率，而另一些用户本身就偏爱浏览而不爱点击。模型分为
Mainnet 和 Biasnet, Mainnet 输入全部特征用于建模用户的隐士反馈，Biasnet
输入用户信息以及 position 信息用于捕捉隐式反馈中的
Bias。最终两个网络的输出相加，通过Sigmoid 函数获得<span class="math inline">\(p(Pay_{all} =1|Drr =1)\)</span></p>
<h4 id="损失函数">损失函数</h4>
<p>通过MLP
Layer之后，最终的损失函数如下，训练数据集为上一阶段的正样本和随机负采样的样本集合，其中全网成交的样本标签为1，随机负采样的样本标签为0。
<span class="math display">\[
Loss_{Pay} = -\frac{1}{N}\sum_{(x,y)\in D}^{N}(y\log p(x) +
(1-y)\log(1-p(x)))
\\
\]</span> <span class="math display">\[
y =\begin{cases}&amp;1,\ 如果x是全网成交 \\
&amp;0,\ 如果x不是全网成交\\
\end{cases}
\]</span></p>
<p>建模第二部分的损失函数同上，只是label和训练数据集不同。</p>
<h1 id="ctnet">CTNet</h1>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2208.05728.pdf">《Continual Transfer
Learning for Cross-Domain Click-Through Rate Prediction at
Taobao》</a></p>
<h2 id="方法-1">方法</h2>
<p>分析现有的学术界和工业界的跨域推荐(Cross-Domain
Recommendation,CDR）的相关工作，主要可分为两大类：联合训练 (Joint
Learning）和预训练-微调 (Pre-training &amp;
Fine-tuning)。其中，联合训练方法同时优化源域(Source Domain）和目标域
(Target
Domain）模型。然而，这一类方法需要在训练中引入源域的数据，而源域数据通常规模很大，从而消耗巨大的计算和存储资源，很多较小业务难以承担如此大的资源开销。另一方面，这一类方法需同时优化多个场景目标，场景之问的差异也可能带来目标冲突的负面影响，因此预训练-微调类方法在工业界很多场景有着更广泛的应用。
工业界推荐系统一个重要的特点是模型训练遵循连续学习 (Continual
Learning）范式，即模型需要使用最新的用户反馈数据，利用离线增量更新
(incremental Learning)或在线学习 (Online
Learning）等方式学习最新的用户兴趣分布。
对于本文研究的跨域推荐任务而言，源域和目标域的模型都是遵循连续学习的训练方式。我们由此提出了一个学术和工业上将有广泛应用的新问题：连续迁移学习
(Continual Transfer
Learning），定义为从一个随时间变化的领域到另一个也随时间变化的领域的知识迁移。我们认为，现有的跨域推荐和迁移学习方法在工业推荐系统、搜索引擎、计算广告等的应用应当遵循连续迁移学习范式，即迁移的过程应当是持续的、多次的。原因在于用户的兴趣分布变化较快，只有通过连续的迁移才可以保证稳定的迁移效果。结合这一工业推荐系统的特点，我们可以发现预训练-微调在实际应用上的问题。由于源域和目标域的场景差异，通常需要用非常大规模的数据（例如数百亿样本）才可以利用源域模型调到一个效果较好的结果。而为了实现连续迁移学习，我们需要每隔一段时间都利用最新的源域模型重新微调，造成了非常巨大的训练代价，这样的训练方式也是难以上线的。此外，利用这些大规模的数据微调也可能使得源域模型遗忘掉保留的有用知识；利用源域模型参数去替换掉原有的目标域已经学好的参数也丢弃了原有模型历史上获得的有用知识。因此，我们需要设计一个更加高效，适用于工业推荐场景的连续迁移学习模型。
本文提出了一个简单有效的模型CTNet (Continual Transfer
Network，连续迁移网络）解決了上述问题。不同手传统的预训练-微调类方法，CTNet的核心思想是不能选忘和丢弃所有模型在历史上获取的知识，保留了原有的源域模型和目标域模型的所有参数。这些参数中保存了通过非常久的历史数据学习得到的知识
（例如淘宝有好货的精排模型已经连续增量训练两年以上）。CTNet采用了简单的双塔结构，利用了一个轻量级的Adapter层将连续预训练
(Continually Pre-trained)
的源域模型中间层表示结果映射并作为目标域模型的额外知识。不同于预训练-微调类方法需回溯数据以实现连续迁移学习，CTNet只需要增量数据进行更新，从而实现了
高效的连续迁移学习。</p>
<h3 id="问题定义">问题定义</h3>
<p>本文探讨的是连续迁移学习这一新问题：给定随时间变化的源域和目标域，连续迁移学习（Continual
Transfer
Learning）希望能够利用历史或者当前获得的源域和目标域知识提升在未来目标域上的预测准确率。本文提出的方法的应用场景具有以下特点：</p>
<ul>
<li>不同的推荐场景规模相差较大，可以利用较大规模数据训练得到的源域模型的知识提升目标域的推荐效果</li>
<li>不同场景的用户和商品共享同一个大底池。但不同场景由于精选商品池、核心用户、图文等展示效果不同存在较为明显的领域差异。</li>
<li>所有推荐场景的模型都是基于最新收集是数据持续增量训练的。</li>
</ul>
<p><img src="/2023/05/25/0525/image-20230525211512666.png"></p>
<p>上图展示了我们的方法部署上线的情景，在<span class="math inline">\(t\)</span>时刻之前源域模型和目标域模型都是只利用各自场景的监督数据单独连续增量训练的。从<span class="math inline">\(t\)</span>
时刻开始，我们在目标域上部署了跨域推荐模型CTNet，该模型将在不能還忘历史上获取的知识的情况，继续在目标域数据上持续增量训练，同时连续不断地从最新的源域模型中迁移知识。</p>
<h2 id="模型-1">模型</h2>
<p><img src="/2023/05/25/0525/image-20230525211739407.png"></p>
<p>我们在原有的目标域的精排模型中嵌入了源域模型的全部特征及其网络参数，形成一个双塔的结构，其中CTNet的左塔为源塔
(Source Tower），右塔为目标塔 (Target
Tower)。不同于常见的只利用源域模型打分分数或只利用一些浅层表示（如Embedding)
的方法，我们通过Adapter网络，将源域模型MLP的所有中问隐藏层(特别是源域MLP深层蕴含的user和item的高阶特征交互信息）的表示结果
z°映射到目标推荐域，并将结果加入到Target
Tower的对应层z中(如下面公式所示）。CTNet效果提升的关键就是利用了MLP中深层表征信息的迁移。借鉴Gated
Linear Units(GLU)的思想，Adapter网络
，采用了门控的线性层，可以有效实现对源域特征的自适应特征选择，模型里有用的知识会做迁移，而与场景特点不符的无用的信息就丢奔掉。由于源域模型持续不断的使用最新的源域监督数据进行连续预训练，在我们的训练过程中，Source
Tower也将持续不断的加载最新更新的源域模型参数并在反向传播过程中保持固定，保证了连续迁移学习的高效进行。模型适用于连续学习范式，使得目标域模型持续的学习到源域模型提供的最新知识，以适应最新的用户兴趣变化。同时由于模型仅在目标域数据上进行训练，保证了模型不受源域训练目标的影响，同时完全不需要源域数据训练，避免了大量的存储和计算开销。此外，这样的网络结构借鉴了无损添加新特征的设计方法，实现了模型的热启动，Target
Tower完全由原有的目标域线上模型初始化，Adapter的初始参数较小，可以在最大程度上保证原有模型的效果不受损害，仅需较少增量数据就可得到很好的效果。</p>
<figure>
<img src="/2023/05/25/0525/image-20230525212156399.png" alt="image-20230525212156399">
<figcaption aria-hidden="true">image-20230525212156399</figcaption>
</figure>
<h1 id="ugic">UGIC</h1>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2208.10174.pdf">《KEEP: An Industrial
Pre-Training Framework for Online Recommendation via Knowledge
Extraction and Plugging》</a></p>
<h2 id="方法-2">方法</h2>
<h3 id="预训练">预训练</h3>
<p>在CV和NLP领域，预训练方法已经被广泛应用于各种主流任务中并取得了很好的效果，尤其在BERT横空出世后，大规模无监督预训练语言模型横扫了NLP各种任务。受BERT影响，CV领域的预训练工作也从有监督预训练开始向无监督预训练转向，MOCO、Simsiam、MAE等一系列优秀的无监督预训练工作也使得视觉领域无监督预训练模型在下游任务的效果可以媲美甚至超过有监督预训练模型。推荐领域的预训练模型也已经被广泛研究，如BERT4ReC,，S3Rec等。这些工作基本沿着预训练语言模型的思路将MLM任务迁移到了用户行为序列上进行预训练，并针对推荐系统的特点对预训练任务进行了一定的微调。
相比BERT4Rec这种无监督预训练方法，我们在实践中选择了一种更为简单的有监督预训练方案，这种选择主要基于以下两点考虑：1、用户在手淘app上的浏览点击行为天然的为我们提供了训练的标签，每天用户在猜你喜欢推荐页大概会产生接近100亿次的曝光行为，常年累月的数据积累使得我们可以轻松的获得海量的有标签数据进行预训练。2、仅在用户行为序列进行无监督预训练本质上还是仅利用了用户的正反馈行为进行表征学习，无法有效利用用户的曝光数据。基于以上考虑我们收集了用户在首猜场景的曝光/点击，点击/加购和点击/购买日志作为我们的预训练样本。其中曝光/点击样本占比超过了95%是预训练样本的主体，点击/加购和点击/购买样本的加入是希望我们的预训练模型可以学习到多种用户兴趣以服务多个下游模型。在用户行为日志的基础上我们构建了曝光/点击(clk)、点击/转化(CV)、点击/加购(cart)三种预训练预估任务，其中clk预估任务直接采用了常用的pointwise的交叉熵损失，cv和cart预估任务除了pointwise
loss外还额外引 了pairwise
loss来缓解任务的稀疏性，最后三个预估任务以multi-task的方式结合在一起，网络结构示意图如下</p>
<p><img src="/2023/05/25/0525/image-20230525213056789.png"></p>
<p>同时在实践中我们发现，预训练的样本量对最后的效果有着至关重要的影响，预训练样本量从1个月提高到6个月再到年，在预训练任务上的test
auc指标分别会有1个百分点以上的提升，在下游任务的主模型中离线gauc也会从无任何提升到点几个千分点的提升再到4点几个千分点的提升，具体数据见在离线效果部分，因此我们最终上线的方案采用了用户过去两年在首猜上的行为日志作为我们的预训练数据。</p>
<h3 id="特征选择模型结构">特征选择&amp;模型结构</h3>
<p>如前文所述，用户每天在首猜场景会产生约100亿的行为数据，而我们的预训练任务的目标是要利用用户两年时间的累积数据。如此庞大的预训练数据量给我们的预训练任务带来了非常大的挑战，为了能够尽量加快模型训练速度，我们一方面尽量精简了模型的输入特征，另一方面也采用了尽量简单的模型结构。
具体而言，特征选择方面我们仅选择了主模型的极小一部分特征子集来构建我们的预训练模型，item侧特征我们仅保留了item_id、
cate_ id
shop_id几个最重要的id特征，用户行为特征我们也仅保留了一条用户行为序列，整体特征量约是主模型的1%。除了主模型特征子集，我们也在预训练任务中加入了更为稀疏的user
ic特征。user_id的全特征空间约有10亿+，在我们的主模型中直接加入这一特征会面临严重的过拟合问题(该现象我们目前仅有一些不成熟的猜想，还没有定论，也欢迎大家一起讨论)，但是在大了两个数量级的预训练数据上，我们相信可以对更加稀疏的user_id充分的训练，同时user_id庞大的参数空间可以给我们的预训练模型提供更好的记忆性，从而得到更好的表征用于下游任务。
模型结构部分我们选择采用了最简单的DNN结构，同时仅在用户行为序列和target
item之间加入了attention
模块，去掉了计算更加耗时的GRU等模块。通过特征逆择和模型结构的精简，以及batch_size的调整，与主模型相比，预训练任务的训练加速比提升了约100倍，除此之外，我们还对负样本进行了随机负采样，仅保留1/5的负样本来进一步加速训练，这些操作使得我们有能力在大约1周左右的时问里完成2年数据的预训练。
预训练任务的模型结构和特征精简本质上是在预训练模型能力和训练样本量之问进行trade
off，
目前我们的经验来看预训练数据量的影响远大于精细的预训练模型结构的影响。</p>
<h3 id="预训练知识表征">预训练知识表征</h3>
<p>我们认为预训练好的预训练模型参数中encode了从预训练数据中抽取到的知识，因此我们用预训练模型一些层的输出作为预训练的知识表征。我们定义的预训练知识表征可以分为3个方面user-level,
item-level,
user-item-iteration-level。其中user-level的知识表征用user_id的embedding来表示，记为<span class="math inline">\(\mathscr{K}_u\)</span>，item-level的知识表征用item特征的embedding来表示，记为<span class="math inline">\(\mathscr{K}_i\)</span>，user-item-interaction-level的知识表征用fc的倒数第二层输出表表示，记为<span class="math inline">\(\mathscr{K}_{ui}\)</span>，同时由于存在3个预训练任务，因此<span class="math inline">\(\mathscr{K}_{ui}\)</span>会有三种不同的表现形式分别记为<span class="math inline">\(\mathscr{K}_{ui}^{clk}\)</span>,<span class="math inline">\(\mathscr{K}_{ui}^{cv}\)</span>,<span class="math inline">\(\mathscr{K}_{ui}^{cart}\)</span>。最终我们将所有抽取到的知识concat到一起供给下游模型。
<span class="math display">\[
\mathscr{K}(u,i) =
[\mathscr{K}_u,\mathscr{K}_i,\mathscr{K}_{ui}^{clk},\mathscr{K}_{ui}^{cv},\mathscr{K}_{ui}^{cart}]
\]</span></p>
<h3 id="预训练知识表征与主模型融合">预训练知识表征与主模型融合</h3>
<p>在利用预训练模型抽取到合适的知识表征之后，接下来就是要把抽取到的预训练知识表征合理的应用到下游任务中。传统的预训练模型在应用中通常是采用pre-training
&amp;
fine-tuning机制，即在下游任务中，加载pre-training参数作为模型参数的初始化，然后在下游任务的训练样本上进行finetune。
然而这种pre-training &amp;
fine-tuning机制在实际的工业级推荐系统中并不完全适用。一方面，线上服务的模型常采用参数增量更新的ODL模式，即每次模型训练都会完全加载之前一个版本的模型参数，然后利用此后一段时间的训练数据进行参数更新，如此循环下去如下图所示。在我们的线上系统中，线上服务的模型己经滚动更新了超过1年以上的时间。在此模式下如果仅将预训练模型参数作为模型初始化，那在后续的增量训练过程中可能会遇到灾难遗忘问题(catastrophic
forgetting)，实践中我们也确实发现仅加载预训练参数作为下游任务模型初始化参数虽然能够有效的加快模型收敛速度，但是随着训练过程的进行，效果gap会逐渐缩小至完全无提升。另一方面，预训练模型同样也需要在用户行为日志上持续进行增量训练以捕捉用户最新兴趣，pre-training
&amp; fine-tuning机制也难以满足预训练模型的参数更新需求。</p>
<p><img src="/2023/05/25/0525/image-20230525214122824.png"></p>
<p>针对以上问题，我们采用了另一种预训练知识表征的融入方式，将预训练知识表征作为下游任务模型的额外输入，帮助下游任务更好的进行预估。同时为了够更好的保留主模型的网络结构，我们设计了一个Knowledge
Plug-in
Network结构，用加法操作代替了传统新加特征的concat操作。这种结构的好处一方面是得主模型可以加载之前版本的模型参数，避免了从随机初始化重新训练，实现特征“热后动”的功能。另一方面在预训练知识表征发生更新时（如新增了一组知识表征时）也可以通过finetune较少的模型参数快速上线，给预训练知识表征保留了一定的拓展空间</p>
<p><img src="/2023/05/25/0525/image-20230525214546148.png"></p>
<h2 id="在线服务">在线服务</h2>
<p>到目前为止我们所尝试的算法方案都非常的简单，对于各种问题基本上就是直觉上的解法，并没有花里胡哨的模型结构设计和算法堆砌。然而预训练模型在工业级推荐系统的应用其实不仅是一个算法问题，一个通用的大规模预训练模型如果想在工业级推荐系统上大规模上线必须要解决好预训练模型的在线服务问题，即如何在满足线上存储和r约束的条件下，高效的服务好多个下游模型，并且不会影响下游模型的迭代节奏。接下来，我们将详细介绍我们将预训练模型在定向广告业务上进行线上服务的经验。</p>
<h3 id="分解和退化策略">分解和退化策略</h3>
<p>为了不给下游任务增加额外的算力负担，我们采用的是缓存策略将预训练模型提取到的知识表征cache在高性能参数服务器中，这样下游任务可以直接请求对应的预训综知识表征<span class="math inline">\(\mathscr{K}(u,i)\)</span>而无需额外的实时计算。然而直接缓存<span class="math inline">\(\mathscr{K}(u,i)\)</span>需要遍历所有的(u,i)
pair，对于手淘约10<sup>9量级的用户空间以及10</sup>9量级的商品空问，组合起来的大(4，2)数量将达到恐怖的10^18，如此大的量级肯定无法直接缓存。对于这一问题我们设计了预训练知识表征的分解和退化策略。</p>
<p>分解策略是指将预训练模型结构分解成双塔结构，从user塔和item塔分别得到
<span class="math inline">\(\mathscr{K}_u,\mathscr{K}_i\)</span>然后用二者的乘积来表征<span class="math inline">\(\mathscr{K}_{ui}\)</span>。然而这种简单的双塔模型结构无法有效的捕捉
<span class="math inline">\(\mathscr{K}_u,\mathscr{K}_i\)</span>之间的高阶交叉关系，因此在分解策略的基础上，我们又增加了退化策略。退化策略是指将模型的打分粒度人item粒度退化至更粗的cate粒度，因为cate的空间远小于item，使得我们可以直接遍历(u，c)
pair进行缓存。 <span class="math display">\[
\mathscr{K}(u,i) \rightarrow \mathscr{K}(u,i,c) =
[\mathscr{K}_u,\mathscr{K}_i,\mathscr{K}_u \times \mathscr{K}_i
,\mathscr{K}_{uc}]
\]</span>
分解策略和退化策略的组合使得我们可以同时拥有细粒度的打分能力和复杂模型的特征交叉能力，并且预训练知识表征的缓存空间大小也从<span class="math inline">\(N_u*N_i\)</span>。减少到<span class="math inline">\(N _u+ N_i+ N_u*N_c\)</span>。</p>
<figure>
<img src="/2023/05/25/0525/image-20230525215321332.png" alt="image-20230525215321332">
<figcaption aria-hidden="true">image-20230525215321332</figcaption>
</figure>
<h3 id="ugic服务">UGIC服务</h3>
<p>定向广告业务繁多，旦每个业务场景下会包括粗排/精排两个阶段，每个阶段下又会有ctrlcvr/cart等预估模型，组合起来目前线上几乎有40+的模型在同时服务主流量，于此同时还有相当数量的实验模型在小流量服务。经过大规模预训练的知识表征可以认为编码了
用户长期且稳定的兴趣偏好，实验证明预训练表征至个场景多个阶段多个任务的下游模型均能带来一定的提升。为了能够方便的服务多个下游模型，我们将预训练知识表征服务从RTP中抽离出来，构建了UGIC(User
General nterest
Center)服务。具体而言，经过分解和退化策略，使得我们有能力将预训练知识表征在UGIC进行缓存，服务过程中，UGIC接收一个(u，i,c）
的pair，并返口对应的知识表征下<span class="math inline">\(\mathscr{K}(u,i,c)\)</span>。同时考虑到预训练模型与下游模型的更新己经解耜，不同的下游任务可能会对应不同的预训练模型版本，为了保证在离线一致性，我们在UGIC中也增加了多版本的服务能力，下游任务可以根据自己特定的版本号v访问相应的预训练知识表征，具体过程如下图所示。</p>
<p><img src="/2023/05/25/0525/image-20230525215520586.png"></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="http://kerwinblog.top">mmmmlz</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://kerwinblog.top/2023/05/25/0525/">http://kerwinblog.top/2023/05/25/0525/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/RS/">RS</a></div><div class="post_share"><div class="social-share" data-image="/img/11.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/06/02/20230601/" title="When Search Meets Recommendation"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">When Search Meets Recommendation</div></div></a></div><div class="next-post pull-right"><a href="/2023/05/20/0520/" title="Optimizing Feature Set for Click-Through Rate Prediction"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">Optimizing Feature Set for Click-Through Rate Prediction</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2023/05/20/0520/" title="Optimizing Feature Set for Click-Through Rate Prediction"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-05-20</div><div class="title">Optimizing Feature Set for Click-Through Rate Prediction</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/11.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">mmmmlz</div><div class="author-info__description">great ideas in CV&RS</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">23</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">8</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">2</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/mmmmlz"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">Focus on the latest developments in recommendation algorithms, advertising algorithms, large models, etc.</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%85%A8%E5%9F%9F%E5%AD%A6%E4%B9%A0"><span class="toc-number">1.</span> <span class="toc-text">全域学习</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%B9%E6%B3%95"><span class="toc-number">1.1.</span> <span class="toc-text">方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BD%A2%E5%BC%8F%E5%8C%96%E5%AE%9A%E4%B9%89"><span class="toc-number">1.1.1.</span> <span class="toc-text">形式化定义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.1.2.</span> <span class="toc-text">模型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#embedding-layer"><span class="toc-number">1.1.2.1.</span> <span class="toc-text">Embedding Layer</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#layer-normal-target-attention-layer"><span class="toc-number">1.1.2.2.</span> <span class="toc-text">Layer Normal Target
Attention Layer</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#mlp-layer"><span class="toc-number">1.1.2.3.</span> <span class="toc-text">MLP layer</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">1.1.2.4.</span> <span class="toc-text">损失函数</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#ctnet"><span class="toc-number">2.</span> <span class="toc-text">CTNet</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%B9%E6%B3%95-1"><span class="toc-number">2.1.</span> <span class="toc-text">方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%97%AE%E9%A2%98%E5%AE%9A%E4%B9%89"><span class="toc-number">2.1.1.</span> <span class="toc-text">问题定义</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B-1"><span class="toc-number">2.2.</span> <span class="toc-text">模型</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#ugic"><span class="toc-number">3.</span> <span class="toc-text">UGIC</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%B9%E6%B3%95-2"><span class="toc-number">3.1.</span> <span class="toc-text">方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A2%84%E8%AE%AD%E7%BB%83"><span class="toc-number">3.1.1.</span> <span class="toc-text">预训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84"><span class="toc-number">3.1.2.</span> <span class="toc-text">特征选择&amp;模型结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9F%A5%E8%AF%86%E8%A1%A8%E5%BE%81"><span class="toc-number">3.1.3.</span> <span class="toc-text">预训练知识表征</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9F%A5%E8%AF%86%E8%A1%A8%E5%BE%81%E4%B8%8E%E4%B8%BB%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88"><span class="toc-number">3.1.4.</span> <span class="toc-text">预训练知识表征与主模型融合</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9C%A8%E7%BA%BF%E6%9C%8D%E5%8A%A1"><span class="toc-number">3.2.</span> <span class="toc-text">在线服务</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E8%A7%A3%E5%92%8C%E9%80%80%E5%8C%96%E7%AD%96%E7%95%A5"><span class="toc-number">3.2.1.</span> <span class="toc-text">分解和退化策略</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ugic%E6%9C%8D%E5%8A%A1"><span class="toc-number">3.2.2.</span> <span class="toc-text">UGIC服务</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/03/07/exl0ikam50/" title="No title">No title</a><time datetime="2024-03-07T12:03:00.753Z" title="Created 2024-03-07 20:03:00">2024-03-07</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/06/02/20230601/" title="When Search Meets Recommendation">When Search Meets Recommendation</a><time datetime="2023-06-02T13:21:12.000Z" title="Created 2023-06-02 21:21:12">2023-06-02</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/05/25/0525/" title="他山之石————推荐系统中的跨域建模">他山之石————推荐系统中的跨域建模</a><time datetime="2023-05-25T11:01:41.000Z" title="Created 2023-05-25 19:01:41">2023-05-25</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/05/20/0520/" title="Optimizing Feature Set for Click-Through Rate Prediction">Optimizing Feature Set for Click-Through Rate Prediction</a><time datetime="2023-05-20T11:01:41.000Z" title="Created 2023-05-20 19:01:41">2023-05-20</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/05/12/rl-05/" title="强化学习笔记5————AC与PPO">强化学习笔记5————AC与PPO</a><time datetime="2023-05-12T13:00:18.000Z" title="Created 2023-05-12 21:00:18">2023-05-12</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('/img/7.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By mmmmlz</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container').forEach(node => {
            if (node.hasAttribute('display')) {
              btf.wrap(node, 'div', { class: 'mathjax-overflow' })
            } else {
              btf.wrap(node, 'span', { class: 'mathjax-overflow' })
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script></div></body></html>